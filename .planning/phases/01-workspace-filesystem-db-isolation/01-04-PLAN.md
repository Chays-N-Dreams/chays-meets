---
phase: 01-workspace-filesystem-db-isolation
plan: 04
type: execute
wave: 4
depends_on: ["01-03"]
files_modified:
  - frontend/src-tauri/src/workspace/migration.rs
  - frontend/src-tauri/src/workspace/mod.rs
  - frontend/src-tauri/src/database/setup.rs
autonomous: false

must_haves:
  truths:
    - "Existing meetings, transcripts, and summaries from meeting_minutes.sqlite are accessible in the Default workspace after migration"
    - "API keys and settings from the old database are accessible via global.sqlite after migration"
    - "Original database is backed up before any migration operations"
    - "Migration only runs once (detected by presence of existing DB + absence of workspaces)"
    - "Zero data loss: meeting count in Default workspace matches original DB"
  artifacts:
    - path: "frontend/src-tauri/src/workspace/migration.rs"
      provides: "migrate_existing_database_to_workspace() function"
      contains: "migrate_existing"
    - path: "frontend/src-tauri/src/database/setup.rs"
      provides: "Migration detection and invocation in workspace initialization"
      contains: "migrate_existing"
  key_links:
    - from: "frontend/src-tauri/src/workspace/migration.rs"
      to: "frontend/src-tauri/src/workspace/manager.rs"
      via: "uses WorkspaceManager to create workspace and switch to it"
      pattern: "WorkspaceManager"
    - from: "frontend/src-tauri/src/database/setup.rs"
      to: "frontend/src-tauri/src/workspace/migration.rs"
      via: "calls migration when existing DB detected with no workspaces"
      pattern: "migration::"
---

<objective>
Implement the migration path from the single meeting_minutes.sqlite database to the workspace architecture, ensuring zero data loss for existing users upgrading to v0.3.0.

Purpose: Users who have been using Meetily have all their meetings, transcripts, summaries, and settings in a single `meeting_minutes.sqlite` file. This plan creates a migration that (1) backs up the original DB, (2) creates a "Default" workspace, (3) copies meeting data into the workspace's db.sqlite, (4) extracts settings/API keys into global.sqlite, and (5) verifies data integrity.

Output: A migration module that runs automatically on first launch after upgrade, with backup safety and data verification.
</objective>

<execution_context>
@/Users/chaysenrathert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/chaysenrathert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-workspace-filesystem-db-isolation/01-CONTEXT.md
@.planning/phases/01-workspace-filesystem-db-isolation/01-RESEARCH.md

# Prior plan outputs
@.planning/phases/01-workspace-filesystem-db-isolation/01-01-SUMMARY.md
@.planning/phases/01-workspace-filesystem-db-isolation/01-02-SUMMARY.md
@.planning/phases/01-workspace-filesystem-db-isolation/01-03-SUMMARY.md

# Key source files
@frontend/src-tauri/src/workspace/manager.rs
@frontend/src-tauri/src/database/setup.rs
@frontend/src-tauri/src/database/manager.rs
@frontend/src-tauri/migrations/20250916100000_initial_schema.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement existing database migration to workspace architecture</name>
  <files>
    frontend/src-tauri/src/workspace/migration.rs
    frontend/src-tauri/src/workspace/mod.rs
    frontend/src-tauri/src/database/setup.rs
  </files>
  <action>
**Part A: Create `workspace/migration.rs`**

Create a migration module with the main migration function:

```rust
pub async fn migrate_existing_database_to_workspace(
    workspace_mgr: &WorkspaceManager,
    existing_db_path: &Path,
) -> Result<String, String>
```

This function should execute the following steps IN ORDER:

**Step 1: Backup**
- Copy `existing_db_path` to `{existing_db_path}.pre-workspace-backup`
- Also copy any `.wal` and `.shm` files if they exist
- Log: "Backed up existing database to {backup_path}"

**Step 2: Checkpoint existing DB WAL**
- Open a temporary SqlitePool to the existing DB
- Execute `PRAGMA wal_checkpoint(TRUNCATE)` to flush any pending WAL changes
- Close this temporary pool

**Step 3: Create Default workspace**
- Call `workspace_mgr.create_workspace("Default".to_string()).await`
- This creates the directory structure and updates the registry
- Store the returned workspace UUID

**Step 4: Copy meeting data to workspace DB**
- The workspace DB path is `{workspace_mgr.workspaces_root()}/{default_id}/db.sqlite`
- Copy the existing DB file to the workspace DB path: `std::fs::copy(existing_db_path, &ws_db_path)`
- Open a temporary pool to the workspace DB copy
- Drop global-only tables from the workspace copy (they don't belong in workspace DB):
  - `DROP TABLE IF EXISTS settings`
  - `DROP TABLE IF EXISTS transcript_settings`
  - `DROP TABLE IF EXISTS licensing`
  - `DROP TABLE IF EXISTS custom_openai_config`
- Drop the `_sqlx_migrations` table to allow fresh workspace migrations to run:
  - `DROP TABLE IF EXISTS _sqlx_migrations`
- Close the temporary pool

**Step 5: Extract settings into global DB**
- Open a temporary pool to the ORIGINAL existing DB (not the workspace copy)
- Read all rows from `settings` table
- Read all rows from `transcript_settings` table
- Read all rows from `licensing` table (if exists)
- Read all rows from `custom_openai_config` table (if exists)
- Insert these rows into the global DB via `workspace_mgr.global_pool()`
- Use `INSERT OR REPLACE` to handle any existing rows
- Close the temporary pool to the existing DB
- Log row counts: "Migrated {N} settings rows, {M} transcript_settings rows"

For reading settings, use `sqlx::query()` with dynamic column handling since the schema may vary across versions. The simplest approach:
- Query `SELECT * FROM settings LIMIT 1` and check what columns exist
- Use `sqlx::query("SELECT sql FROM sqlite_master WHERE type='table' AND name='settings'")` to get the CREATE TABLE statement, then insert matching columns into global DB
- OR simply do: `ATTACH DATABASE '{global_db_path}' AS global_db; INSERT INTO global_db.settings SELECT * FROM settings;` -- BUT this requires the schemas to match exactly.

**Safest approach:** Since the global migration SQL creates the same tables with the same schema, use ATTACH DATABASE:
1. Open a connection to the workspace DB copy (which still has the old tables at this point before we dropped them -- wait, we already dropped them in Step 4)

**Revised order:** Do Step 5 BEFORE Step 4's table drops. The corrected flow:
1. Backup (Step 1)
2. WAL checkpoint (Step 2)
3. Create Default workspace (Step 3)
4. Copy existing DB to workspace path
5. Extract settings from the workspace copy into global DB (Step 5) -- BEFORE dropping tables
6. Drop global tables from workspace copy + drop _sqlx_migrations (Step 4)
7. Close pools

Actually, even simpler: extract settings from the ORIGINAL existing DB, not from the copy:

1. Backup original
2. Checkpoint original WAL
3. Create Default workspace
4. Copy original to workspace DB path
5. Extract settings from ORIGINAL into global DB
6. Clean workspace copy: drop settings tables + _sqlx_migrations

For the extraction, use individual column queries to avoid schema mismatch:
```rust
// Read settings from original DB
let rows = sqlx::query("SELECT * FROM settings")
    .fetch_all(&original_pool).await;

// For each row, insert into global DB
// Use sqlx::query with explicit column names
```

Use `sqlx::Row` trait to read columns dynamically: `row.try_get::<String, _>("column_name")`.

**Step 6: Switch to Default workspace**
- Call `workspace_mgr.switch_workspace(&default_id).await`
- This opens the workspace DB pool and runs workspace migrations

**Step 7: Verify migration integrity**
- Count meetings in Default workspace: `SELECT COUNT(*) FROM meetings`
- Count meetings in backup/original: reopen original pool, count
- Log: "Migration verification: {original_count} meetings in original, {workspace_count} in Default workspace"
- If counts don't match, log a WARNING (don't fail -- the user can restore from backup)
- Return the default workspace UUID

**Part B: Update `workspace/mod.rs`**
Add `pub mod migration;` to the module declarations.

**Part C: Integrate migration into `database/setup.rs`**

In the `initialize_workspace_manager()` function, update the migration detection branch:

Where the current Plan 03 left a placeholder:
```
"Existing database found but no workspaces. Migration will be handled separately."
```

Replace with actual migration invocation:
```rust
let existing_db = app_data_dir.join("meeting_minutes.sqlite");
if existing_db.exists() && workspace_mgr.list_workspaces().await.is_empty() {
    log::info!("Existing database found with no workspaces. Starting migration...");
    match workspace::migration::migrate_existing_database_to_workspace(
        &workspace_mgr,
        &existing_db,
    ).await {
        Ok(default_id) => {
            log::info!("Migration complete. Default workspace created: {}", default_id);
        }
        Err(e) => {
            log::error!("Migration failed: {}. Creating empty Default workspace.", e);
            // Fallback: create empty workspace so app is usable
            let fallback_id = workspace_mgr.create_workspace("Default".to_string()).await
                .map_err(|e| format!("Failed to create fallback workspace: {}", e))?;
            workspace_mgr.switch_workspace(&fallback_id).await
                .map_err(|e| format!("Failed to switch to fallback workspace: {}", e))?;
        }
    }
}
```

Also handle audio file paths: Per RESEARCH.md recommendation, keep existing `folder_path` references in meeting records as-is. New recordings will go into the workspace's `audio/` folder. Do NOT attempt to move audio files during migration.
  </action>
  <verify>
1. `cargo check --manifest-path frontend/src-tauri/Cargo.toml` passes with zero errors.
2. Verify migration.rs exists with `migrate_existing_database_to_workspace()` function.
3. Verify database/setup.rs calls migration when existing DB is detected.
4. Verify the migration creates a backup file path pattern.
  </verify>
  <done>
Migration module exists and is integrated into app startup. When existing meeting_minutes.sqlite is detected with no workspaces: (1) original is backed up, (2) Default workspace created, (3) meeting data copied to workspace DB, (4) settings extracted to global DB, (5) data integrity verified by comparing meeting counts.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete workspace filesystem and database isolation system:
- Workspace types and filesystem operations (Plan 01)
- WorkspaceManager with pool lifecycle management (Plan 02)
- All 24+ command handlers rewired from AppState to WorkspaceManager (Plan 03)
- Existing data migration to Default workspace (Plan 04)

The app should now start up, detect existing data, migrate it to a Default workspace, and function normally with all meetings accessible.
  </what-built>
  <how-to-verify>
1. Run `cargo check --manifest-path frontend/src-tauri/Cargo.toml` -- should pass with zero errors
2. Run `./clean_run.sh` from the `frontend/` directory to launch the app
3. Verify the app starts without errors in the terminal log
4. Check terminal output for: "WorkspaceManager initialized", migration-related log messages
5. If you had existing meetings: verify they appear in the meeting list (now in Default workspace)
6. If fresh install: verify the app starts and shows empty meeting list (Default workspace created)
7. Check the filesystem: `ls ~/Library/Application\ Support/Meetily/workspaces/` should show:
   - `workspaces.json` (registry file)
   - `global.sqlite` (global settings DB)
   - A UUID-named directory containing: `manifest.json`, `db.sqlite`, `audio/`, `notes/`, `config.json`
8. If migration ran: verify `meeting_minutes.sqlite.pre-workspace-backup` exists in app data dir
9. Try recording a short meeting -- should work normally (recording goes through active workspace pool)
10. Check that settings are preserved (LLM provider, API keys still configured)
  </how-to-verify>
  <resume-signal>Type "approved" if everything works, or describe any issues you see</resume-signal>
</task>

</tasks>

<verification>
1. `cargo check --manifest-path frontend/src-tauri/Cargo.toml` passes
2. Migration module compiles and is integrated into startup
3. Backup is created before any destructive operations
4. Meeting count verification logged during migration
5. Fallback path exists if migration fails (empty Default workspace)
6. App starts, migrates, and functions normally
</verification>

<success_criteria>
- Existing meetings survive upgrade in Default workspace (zero data loss verified by meeting count comparison)
- API keys and settings accessible via global DB after migration
- Original database backed up at `meeting_minutes.sqlite.pre-workspace-backup`
- Migration is idempotent (if workspaces already exist, migration is skipped)
- App is fully functional after migration: can view meetings, start recordings, access settings
- Workspace directory structure is clean and browsable on disk
</success_criteria>

<output>
After completion, create `.planning/phases/01-workspace-filesystem-db-isolation/01-04-SUMMARY.md`
</output>
