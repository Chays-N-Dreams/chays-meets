---
phase: 01-workspace-filesystem-db-isolation
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified:
  - frontend/src-tauri/src/lib.rs
  - frontend/src-tauri/src/state.rs
  - frontend/src-tauri/src/database/setup.rs
  - frontend/src-tauri/src/api/api.rs
  - frontend/src-tauri/src/summary/commands.rs
  - frontend/src-tauri/src/onboarding.rs
autonomous: true

must_haves:
  truths:
    - "All 24+ database access points use WorkspaceManager instead of AppState"
    - "App startup initializes WorkspaceManager and registers it as Tauri managed state"
    - "App shutdown cleans up active workspace pool via WorkspaceManager"
    - "Settings/API key operations use global_pool() while meeting operations use active_pool()"
    - "The application compiles and existing functionality is preserved (no regressions)"
  artifacts:
    - path: "frontend/src-tauri/src/lib.rs"
      provides: "WorkspaceManager registration in setup hook, cleanup in exit handler"
      contains: "WorkspaceManager"
    - path: "frontend/src-tauri/src/api/api.rs"
      provides: "All 18 command handlers using WorkspaceManager instead of AppState"
      contains: "workspace_mgr"
    - path: "frontend/src-tauri/src/summary/commands.rs"
      provides: "4 summary command handlers using WorkspaceManager"
      contains: "workspace_mgr"
    - path: "frontend/src-tauri/src/onboarding.rs"
      provides: "1 onboarding command handler using WorkspaceManager"
      contains: "workspace_mgr"
    - path: "frontend/src-tauri/src/database/setup.rs"
      provides: "Workspace-aware initialization replacing old initialize_database_on_startup"
      contains: "WorkspaceManager"
  key_links:
    - from: "frontend/src-tauri/src/api/api.rs"
      to: "frontend/src-tauri/src/workspace/manager.rs"
      via: "tauri::State<WorkspaceManager> parameter in every command"
      pattern: "State<'_, WorkspaceManager>"
    - from: "frontend/src-tauri/src/lib.rs"
      to: "frontend/src-tauri/src/workspace/manager.rs"
      via: "app.manage(workspace_manager) in setup hook"
      pattern: "app\\.manage\\(.*workspace"
    - from: "frontend/src-tauri/src/lib.rs"
      to: "frontend/src-tauri/src/workspace/manager.rs"
      via: "close_active_workspace() in exit handler"
      pattern: "close_active_workspace"
---

<objective>
Rewire the entire application from AppState (single database) to WorkspaceManager (multi-workspace). Replace all 24+ `state.db_manager.pool()` call sites with workspace-aware equivalents.

Purpose: This is the integration plan that makes the WorkspaceManager the source of truth for all database access. After this plan, the old AppState struct is retired and every command handler goes through WorkspaceManager. Settings-related queries use `global_pool()` while meeting/transcript queries use `active_pool()`.

Output: All command handlers updated, lib.rs setup/teardown updated, database/setup.rs rewritten for workspace initialization.
</objective>

<execution_context>
@/Users/chaysenrathert/.claude/get-shit-done/workflows/execute-plan.md
@/Users/chaysenrathert/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-workspace-filesystem-db-isolation/01-CONTEXT.md
@.planning/phases/01-workspace-filesystem-db-isolation/01-RESEARCH.md

# Prior plan outputs
@.planning/phases/01-workspace-filesystem-db-isolation/01-01-SUMMARY.md
@.planning/phases/01-workspace-filesystem-db-isolation/01-02-SUMMARY.md

# Files being modified -- READ ALL before editing
@frontend/src-tauri/src/lib.rs
@frontend/src-tauri/src/state.rs
@frontend/src-tauri/src/database/setup.rs
@frontend/src-tauri/src/api/api.rs
@frontend/src-tauri/src/summary/commands.rs
@frontend/src-tauri/src/onboarding.rs
@frontend/src-tauri/src/database/commands.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite database setup and lib.rs for WorkspaceManager</name>
  <files>
    frontend/src-tauri/src/database/setup.rs
    frontend/src-tauri/src/lib.rs
    frontend/src-tauri/src/state.rs
  </files>
  <action>
**Step 1: Rewrite `database/setup.rs`**

Replace the existing `initialize_database_on_startup()` function with a new workspace-aware initialization function:

```rust
pub async fn initialize_workspace_manager(app: &AppHandle) -> Result<WorkspaceManager, String> {
```

This function should:
1. Get app_data_dir via `app.path().app_data_dir()`
2. Call `WorkspaceManager::init(app_data_dir).await`
3. If WorkspaceManager has no workspaces in registry AND no existing `meeting_minutes.sqlite`:
   - This is a genuine first launch. Create a "Default" workspace automatically via `workspace_mgr.create_workspace("Default".to_string()).await`
   - Switch to it via `workspace_mgr.switch_workspace(&default_id).await`
4. If WorkspaceManager has workspaces in registry:
   - If there's a `last_active`, it was already restored during `WorkspaceManager::init()`
   - If no `last_active` but workspaces exist, switch to the first one
5. If there's an existing `meeting_minutes.sqlite` but no workspaces:
   - This is a migration scenario. Do NOT handle migration here -- that's Plan 04.
   - For now, just log a warning: "Existing database found but no workspaces. Migration will be handled separately."
   - Still create a Default workspace and switch to it (the migration plan will populate it)
6. Return the initialized WorkspaceManager

Remove the old `initialize_database_on_startup()` function. Remove the first-launch event emission logic (that's handled differently now).

Import WorkspaceManager from `crate::workspace::manager::WorkspaceManager`.

**Step 2: Update `lib.rs` setup hook**

In the `.setup(|_app| { ... })` closure:

Replace:
```rust
tauri::async_runtime::block_on(async {
    database::setup::initialize_database_on_startup(&_app.handle()).await
})
.expect("Failed to initialize database");
```

With:
```rust
let workspace_manager = tauri::async_runtime::block_on(async {
    database::setup::initialize_workspace_manager(&_app.handle()).await
})
.expect("Failed to initialize workspace manager");
_app.manage(workspace_manager);
log::info!("WorkspaceManager initialized and registered as Tauri state");
```

In the `.run()` exit handler:

Replace:
```rust
if let Some(app_state) = _app_handle.try_state::<state::AppState>() {
    log::info!("Starting database cleanup...");
    if let Err(e) = app_state.db_manager.cleanup().await {
        ...
    }
}
```

With:
```rust
if let Some(workspace_mgr) = _app_handle.try_state::<workspace::manager::WorkspaceManager>() {
    log::info!("Starting workspace manager cleanup...");
    if let Err(e) = workspace_mgr.close_active_workspace().await {
        log::error!("Failed to cleanup active workspace: {}", e);
    } else {
        log::info!("Workspace manager cleanup completed successfully");
    }
}
```

**Step 3: Update `state.rs`**

Keep the `state.rs` file but mark AppState as deprecated or remove it entirely. Since no more code should reference it after this plan, remove the `AppState` struct. Replace the file contents with a comment:
```rust
// AppState has been replaced by WorkspaceManager (crate::workspace::manager::WorkspaceManager).
// This file is kept for module declaration compatibility but contains no active code.
// TODO: Remove this module declaration from lib.rs in a future cleanup.
```

Actually, it's cleaner to just remove `pub mod state;` from lib.rs and delete the file reference. But if other modules import it, check first. Search for `use crate::state` in the codebase. If only database/setup.rs imports it (and we're rewriting that), it's safe to remove.
  </action>
  <verify>
1. `cargo check --manifest-path frontend/src-tauri/Cargo.toml` -- may have errors from command handlers still referencing AppState. That's expected and will be fixed in Task 2. Verify that setup.rs and lib.rs changes compile independently by checking the error output only mentions api.rs, summary/commands.rs, onboarding.rs.
  </verify>
  <done>
database/setup.rs uses WorkspaceManager for initialization. lib.rs registers WorkspaceManager as Tauri state and cleans it up on exit. AppState struct is removed.
  </done>
</task>

<task type="auto">
  <name>Task 2: Rewire all command handlers from AppState to WorkspaceManager</name>
  <files>
    frontend/src-tauri/src/api/api.rs
    frontend/src-tauri/src/summary/commands.rs
    frontend/src-tauri/src/onboarding.rs
    frontend/src-tauri/src/database/commands.rs
  </files>
  <action>
Replace every `state: tauri::State<'_, AppState>` parameter with `workspace_mgr: tauri::State<'_, WorkspaceManager>` across ALL command handler files.

**Critical routing decision for each call site:** Determine whether the command accesses meeting/workspace data OR global settings data:

**Meeting/workspace data (use `workspace_mgr.active_pool().await?`):**
- `api_get_meetings` -- queries meetings table
- `api_search_transcripts` -- queries transcripts table
- `api_get_meeting` -- queries meetings table
- `api_get_meeting_metadata` -- queries meetings table
- `api_get_meeting_transcripts` -- queries transcripts table
- `api_save_meeting_title` -- updates meetings table
- `api_save_transcript` -- inserts into transcripts table
- `api_delete_meeting` -- deletes from meetings table
- All summary commands in `summary/commands.rs` -- access summary_processes, transcript_chunks
- `onboarding.rs` -- if it accesses meetings data

**Global settings data (use `workspace_mgr.global_pool()`):**
- `api_get_profile` -- queries settings table (LLM provider config)
- `api_save_profile` -- updates settings table
- `api_update_profile` -- updates settings table
- `api_get_model_config` -- queries settings table
- `api_save_model_config` -- updates settings table
- `api_get_api_key` -- queries settings table for API keys
- `api_get_transcript_config` -- queries transcript_settings table
- `api_save_transcript_config` -- updates transcript_settings table
- `api_get_transcript_api_key` -- queries transcript_settings table
- `api_save_custom_openai_config` -- queries/updates custom_openai_config table
- `api_get_custom_openai_config` -- queries custom_openai_config table
- `api_test_custom_openai_connection` -- queries custom_openai_config table

For EACH file:
1. Read the file fully first
2. Replace the import: `use crate::state::AppState;` -> `use crate::workspace::manager::WorkspaceManager;`
3. Replace each function signature: `state: tauri::State<'_, AppState>` -> `workspace_mgr: tauri::State<'_, WorkspaceManager>`
4. Replace each pool access:
   - For meeting data: `let pool = state.db_manager.pool();` -> `let pool = workspace_mgr.active_pool().await.map_err(|e| e.to_string())?;` (note: this returns owned SqlitePool, not reference -- adjust usage if needed by using `&pool`)
   - For settings data: `let pool = state.db_manager.pool();` -> `let pool = workspace_mgr.global_pool();` (this returns &SqlitePool)

**Important:** The `active_pool()` method is async and returns `Result<SqlitePool, String>`. This means:
- Functions calling it must be async (they already are -- all Tauri commands are async)
- The returned pool is owned (cloned from the inner pool). Pass `&pool` to repository methods that expect `&SqlitePool`
- The error case handles "no active workspace" gracefully

**For `database/commands.rs`:**
Read this file to check if it references AppState. The commands (`check_first_launch`, `import_and_initialize_database`, `initialize_fresh_database`, etc.) deal with legacy database operations. These need special handling:
- `check_first_launch` -- should now check if workspaces exist (delegate to WorkspaceManager)
- `import_and_initialize_database` -- this is legacy import flow. For now, have it call WorkspaceManager methods. If it's complex, mark it with a TODO for the migration plan (Plan 04).
- `initialize_fresh_database` -- should create a workspace and switch to it via WorkspaceManager
- Keep the existing function signatures for the Tauri commands but change the internal implementation

**DO NOT modify the command names or remove any commands.** The frontend still calls these by name. Only change the internal implementation to go through WorkspaceManager.

After all changes, remove the `use crate::state::AppState;` import from all files. If state.rs still exists, clean it up or remove `pub mod state;` from lib.rs (check no other imports remain).
  </action>
  <verify>
1. `cargo check --manifest-path frontend/src-tauri/Cargo.toml` passes with ZERO errors.
2. Search for remaining `AppState` references: `grep -r "AppState" frontend/src-tauri/src/` should return ZERO results (or only in comments).
3. Search for remaining `state.db_manager` references: `grep -r "state\.db_manager" frontend/src-tauri/src/` should return ZERO results.
4. Verify the correct pool routing: settings commands use `global_pool()`, meeting commands use `active_pool()`.
  </verify>
  <done>
All 24+ call sites are converted from AppState to WorkspaceManager. Meeting/workspace data routes through active_pool(). Settings/API key data routes through global_pool(). The application compiles with zero errors. AppState is completely removed.
  </done>
</task>

</tasks>

<verification>
1. `cargo check --manifest-path frontend/src-tauri/Cargo.toml` passes with zero errors
2. `grep -r "AppState" frontend/src-tauri/src/ --include="*.rs"` returns zero matches (or only comments)
3. `grep -r "state\.db_manager" frontend/src-tauri/src/ --include="*.rs"` returns zero matches
4. lib.rs setup creates and manages WorkspaceManager
5. lib.rs exit handler calls close_active_workspace()
6. Settings commands use global_pool(), meeting commands use active_pool()
</verification>

<success_criteria>
- Application compiles with zero errors
- Zero references to AppState remain in active code
- All database access goes through WorkspaceManager
- Settings are routed to global_pool (always available)
- Meeting data is routed to active_pool (requires active workspace)
- App starts up, initializes WorkspaceManager, creates Default workspace if fresh install
- App shutdown properly cleans up workspace pool
</success_criteria>

<output>
After completion, create `.planning/phases/01-workspace-filesystem-db-isolation/01-03-SUMMARY.md`
</output>
